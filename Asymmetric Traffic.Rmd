---
title: "Asymmetric Traffic"
author: "Josh Hartman"
date: "November 25, 2020"
output: 
  html_document:
    number_sections: true
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Explore the data
```{r, cache=TRUE}
# attach package readr to read zip files
#library("readr")
#Jan <- read_csv("201901-citibike-tripdata.csv.zip")
#Feb <- read_csv("201902-citibike-tripdata.csv.zip")
#Mar <- read_csv("201903-citibike-tripdata.csv.zip")
#Apr <- read_csv("201904-citibike-tripdata.csv.zip")
#May <- read_csv("201903-citibike-tripdata.csv.zip")
#Jun <- read_csv("201903-citibike-tripdata.csv.zip")
#Jul <- read_csv("201903-citibike-tripdata.csv.zip")
#Aug <- read_csv("201903-citibike-tripdata.csv.zip")
#Sep <- read_csv("201903-citibike-tripdata.csv.zip")
#Oct <- read_csv("201903-citibike-tripdata.csv.zip")
#Nov <- read_csv("201903-citibike-tripdata.csv.zip")
#Dec <- read_csv("201903-citibike-tripdata.csv.zip")
#combine all files
#combo <- rbind(Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec)
#take a sample of to work with by attaching dplyr package and taking a 5% sample
#library("dplyr")
#citibikesample <- sample_frac(combo, 0.05)
#convert to csv
#write.csv(citibikesample,"citibikesample.csv")
#viewing structure of sample
citibikesample <- read.csv("citibikesample.csv", stringsAsFactors = TRUE)


```
# Clean Data

```{r, cache=TRUE}
# convert relevant fields to factors
citibikesample$bikeid <- as.factor(citibikesample$bikeid)

#convert 1 and 2 to m and f

citibikesample$gender <- ifelse(citibikesample$gender == 1| citibikesample$gender == "M", "M",ifelse(citibikesample$gender == 2| citibikesample$gender ==  "F","F", NA))
  
citibikesample$gender<- as.factor(citibikesample$gender)



#revisualize
str(citibikesample)
```

# Load Packages
```{r }
# attach ggplot package
library("ggplot2")
# attach dplyr
library("dplyr")
# attach scales
library("scales")

#attach all packages

library("leaflet")
library("sp")
library("ggmap")
#D. Kahle and H. Wickham. ggmap: Spatial Visualization with ggplot2. The R Journal, 5(1), 144-161. URL http://journal.r-project.org/archive/2013-1/kahle-wickham.pdf

library("maptools")
library("httr")
library(gganimate)
```

# Asymmetry Maps
```{r}
#setup for following r chunks

#making a new data.frame that maps count of visits to start staion id
freqstartstationid <- count(citibikesample, start.station.id)
freqstartstationid<- freqstartstationid[order(freqstartstationid$n, decreasing = TRUE),]

#merging this df with existing one by start station id, will add new column n which is the count of the start station id in the original df
freqstartcitibikesample <- merge(citibikesample, freqstartstationid, by.x = "start.station.id", by.y = "start.station.id")
freqstartcitibikesample$n -> freqstartcitibikesample$start.station.count

#taking top occuring start stations and making them a new df, topstartstation
#because the top start stations occur thousands of times, used count of start stations * 2 to get number of rows to include
topstartstation <- head(freqstartcitibikesample[order(freqstartcitibikesample$n, decreasing = TRUE),], n= sum(freqstartstationid[1:3,2]))
topstartstation <- topstartstation[,c(1,7:8, 17:18)]
#get tail of df to display lower occuring start stations and name bottomstartstation
bottomstartstation <- tail(freqstartcitibikesample[order(freqstartcitibikesample$n, decreasing = TRUE), ], n=10)
#repeat for end stations
freqendstationid <- count(citibikesample, end.station.id)
#repeating merge but by end station id
freqendcitibikesample <- merge(citibikesample, freqendstationid, by.x = "end.station.id", by.y = "end.station.id")
#taking top occuring end stations and making them a new df, topendstation
#because the top end stations occur thousands of times, used count of end stations * 2 to get number of rows to include
topendstation <- head(freqendcitibikesample[order(freqendcitibikesample$n, decreasing = TRUE),], n= max(freqendcitibikesample$n)*2)
#get tail of this df to display lower occuring end stations
bottomendstation <- tail(freqendcitibikesample[order(freqendcitibikesample$n, decreasing = TRUE), ], n=10)

#make df to show assym
#make data frame that has lat and long for each start station
locationinfo <- freqstartcitibikesample[,c(1,7,8)]

#merging counts for start and end stations and then merging with location info
assymstation <- merge(freqstartstationid, freqendstationid, by.x = "start.station.id", by.y = "end.station.id")
assymstation_location <- merge(locationinfo, assymstation, by.x = "start.station.id", by.y = "start.station.id")
#removing duplicate rows
assymtraffic <- assymstation_location[!duplicated(assymstation_location$start.station.id),]
#making it easier to understand
assymtraffic$start.station.id -> assymtraffic$station.id
assymtraffic$n.x -> assymtraffic$count.start.station
assymtraffic$n.y -> assymtraffic$count.end.station
#getting rid of these columns
assymtraffic$start.station.id <- NULL
assymtraffic$n.x <- NULL
assymtraffic$n.y <- NULL
#making these vectors integers
assymtraffic$count.start.station <- as.integer(assymtraffic$count.start.station)
assymtraffic$count.end.station <- as.integer(assymtraffic$count.end.station)
#creating new column that determines surplus or deficit by seeing the difference between occurences of start and end stations
assymtraffic$difference <- c(assymtraffic$count.start.station - assymtraffic$count.end.station)
#order so that difference is decreasing
sortedassymstation <- assymtraffic[order(assymtraffic$difference, decreasing = TRUE),]
```

## Top 10 Stations with Surplus
```{r}
#making df with stations that have surplus
surplusstations <- sortedassymstation[sortedassymstation$difference > 0, ]

#get top 10 stations
topsurplusstations <- head(surplusstations, n = 10)

#using sortedassymstation df to make a leaflet showing stations used as an end station more than as a start station
leaflet(topsurplusstations) %>%
  addTiles()%>% #adding map tiles
  addMarkers(data = topsurplusstations, ~start.station.longitude, ~start.station.latitude, popup = paste("Station ID:", topsurplusstations$station.id, "<br>", "Surplus:", topsurplusstations$difference)) %>% #adding markers with station id displayed and the surplus
  setView(-73.96,40.75, zoom = 9)
```

## Top 10 Stations with Deficit
```{r}
#making df with stations that have surplus
deficitstations <- sortedassymstation[sortedassymstation$difference < 0, ]

#get top 10 stations
bottomdeficitstations <- tail(deficitstations, n = 10)

#using sortedassymstation df to make a leaflet showing stations used as an end station more than as a start station
leaflet(bottomdeficitstations) %>%
  addTiles()%>% #adding map tiles
  addMarkers(data = bottomdeficitstations, ~start.station.longitude, ~start.station.latitude, popup = paste("Station ID:", bottomdeficitstations$station.id, "<br>", "Deficit:", bottomdeficitstations$difference)) %>% #adding markers with station id displayed and the surplus
  setView(-73.96,40.75, zoom = 9)
```

# Asymmetry by Time
## Top 5 Surplus and Top 5 Deficits By Day
```{r}

# lubridate package to get date times
library("lubridate"); library("chron");library("timeDate")

#getting relevant vectors from sample data
datafortime <- citibikesample[,c(3:5,7:9,11:14)]

#ymdhms format
datafortime$starttime <- ymd_hms(datafortime$starttime)
datafortime$stoptime <- ymd_hms(datafortime$stoptime)

#make list of holidays 
holidaylist <- c("USChristmasDay","USGoodFriday","USIndependenceDay","USLaborDay",
    "USNewYearsDay","USThanksgivingDay") 

#get dates of holidays for 2019
myholidays  <- floor_date(ymd(as.character(holiday(2019,holidaylist)), "day"))

#omit nas
na.omit(myholidays) -> myholidays

#make a df to later search for name of holiday associated with date
Holidays <- data.frame(unlist(holidaylist, recursive = TRUE))
Holidaydf <- cbind(Holidays,myholidays)

#create new vectors for different time increments
datafortime$month <- month(datafortime$starttime)
datafortime$day <- floor_date(datafortime$starttime, "day")
datafortime$hour <- hour(datafortime$starttime)
datafortime$weekday <- weekdays(datafortime$starttime)
datafortime$roundedhour <- floor_date(datafortime$starttime, "hour")

#make a vector that determines whether a date is a holiday and returns the name of the holiday if it is, else "Not Holiday"
datafortime$holiday <- ifelse(datafortime$day == myholidays[1]|datafortime$day == myholidays[2]|datafortime$day == myholidays[3]|datafortime$day == myholidays[4]|datafortime$day == myholidays[5]|datafortime$day == myholidays[6], Holidaydf[match(datafortime$day, Holidaydf$myholidays),1],"Not Holiday")

#get counts for start and end station ids by day
startstationbyday <- count(datafortime, start.station.id, day)
endstationbyday <- count(datafortime, end.station.id, day)

#combine df's by station id and day
combinedcountbyday <- merge(startstationbyday, endstationbyday, by.x = c("start.station.id","day"), by.y = c("end.station.id","day"))

#make vector of surplus(deficit)
combinedcountbyday$dif <- c(combinedcountbyday$n.x - combinedcountbyday$n.y)

#define day as a date
combinedcountbyday$day <- as.Date(combinedcountbyday$day)

#count start.station occurences so can grab data for 10 total stations
countedstation <- count(combinedcountbyday, start.station.id)

#use countedstation to reference how many rows of combindedcountby day to get for top 5 stations
topcombinedcountbyday <- head(combinedcountbyday, n = sum(countedstation[1:5,2]))

#use countedstation as index for how many rows of combinedcount by day to get for bottom 5 stations
bottomcombinedcountbyday <- tail(combinedcountbyday, n = sum(countedstation[nrow(countedstation)-5:nrow(countedstation),2]))

#bind the rows of top and bottom 5 stations
topbottombyday <- rbind(topcombinedcountbyday,bottomcombinedcountbyday)

#order by station id then day (increasing)
orderedtopbottombyday <- topbottombyday[order(topbottombyday$start.station.id, topbottombyday$day, decreasing = FALSE),]

#make a line plot that plots surplus/deficit by day
surplusplot <- ggplot(topcombinedcountbyday, aes(x= day, y= dif))+ geom_line(color = "darkgreen")+facet_wrap("start.station.id")+labs(x = "Date", y = "Difference")

#make barplot that shows surplus or deficit by day for top 5 and bottom 5 stations
surplusbarplot <- ggplot(topcombinedcountbyday, aes(x= day)) + geom_col(aes(y=dif), color = "darkgreen") + facet_wrap("start.station.id")
surplusbarplot

```

## Monthly
```{r}
#make new df that counts start and end station by month
startstationbymonth <- count(datafortime, start.station.id, month)
endstationbymonth <- count(datafortime, end.station.id, month)

#combine df's by station id and month
combinedcountbymonth <- merge(startstationbymonth, endstationbymonth, by.x = c("start.station.id","month"), by.y = c("end.station.id","month"))

#find surplus(deficit) and make a new vector
combinedcountbymonth$dif <- c(combinedcountbymonth$n.x - combinedcountbymonth$n.y)

#make a plot that shows average surplus(deficit) by month for all stations
group_by(combinedcountbymonth, month)%>%
summarise(
  Dif = mean(dif, na.rm = TRUE))%>%
ggplot(aes(x = month, y= Dif))+geom_col(color = "darkgreen")+xlab("Month") + ylab("Surplus (Deficit)") +ggtitle("Mean Surplus(Deficit) by Month") 


#get count of each station for use as "index" to get a specified number of stations
monthlycountedstation <- count(combinedcountbymonth, combinedcountbymonth$start.station.id)

#make a plot that shows surplus(deficit) by month for 10 stations
head(combinedcountbymonth, n= sum(monthlycountedstation[1:10,2]))%>%
ggplot(aes(x= month, y= dif))+geom_col(color = "darkgreen")+facet_wrap("start.station.id")

```

## Weekday
```{r}
#make new df that counts start and end station by weekday
startstationbyweekday <- count(datafortime, start.station.id, weekday)
endstationbyweekday <- count(datafortime, end.station.id, weekday)

#combine df's by station id and weekday
combinedcountbyweekday <- merge(startstationbyweekday, endstationbyweekday, by.x = c("start.station.id","weekday"), by.y = c("end.station.id","weekday"))

#find surplus(deficit) and make a new vector
combinedcountbyweekday$dif <- c(combinedcountbyweekday$n.x - combinedcountbyweekday$n.y)

#make weekday an ordered factor so display it Monday to Sunday
combinedcountbyweekday$weekday <- ordered(combinedcountbyweekday$weekday, levels = c("Monday", "Tuesday", "Wednesday", "Thursday","Friday", "Saturday", "Sunday"))

#make a plot of mean surplus(deficit) by weekday for all stations
group_by(combinedcountbyweekday, weekday, decreasing = TRUE)%>%
summarise(
  Dif = mean(dif, na.rm = TRUE))%>%
ggplot(aes(x = weekday, y= Dif))+geom_col(color = "darkgreen")+xlab("Weekday") + ylab("Surplus (Deficit)")+ggtitle("Mean Surplus(Deficit) by Weekday") 

#get count of each station for use as "index" to get a specified number of stations
weekdaycountedstation <- count(combinedcountbyweekday, combinedcountbyweekday$start.station.id)

#make a plot that shows surplus(deficit) by weekday for 5 stations
head(combinedcountbyweekday, n= sum(weekdaycountedstation[1:5,2]))%>%
ggplot(aes(x= weekday, y= dif))+geom_col(color = "darkgreen")+facet_wrap("start.station.id")+theme(axis.text.x = element_text(angle=90, hjust=1))
```

## Hour
```{r}
#make new df that counts start and end station by hour
startstationbyhour <- count(datafortime, start.station.id, hour)
endstationbyhour <- count(datafortime, end.station.id, hour)

#combine df's by station id and hour
combinedcountbyhour <- merge(startstationbyhour, endstationbyhour, by.x = c("start.station.id","hour"), by.y = c("end.station.id","hour"))

#find surplus(deficit) and make a new vector
combinedcountbyhour$dif <- c(combinedcountbyhour$n.x - combinedcountbyhour$n.y)

#make a plot that shows average surplus(deficit) by hour for all stations
group_by(combinedcountbyhour, hour, decreasing = TRUE)%>%
summarise(
  Dif = mean(dif, na.rm = TRUE))%>%
ggplot(aes(x = hour, y= Dif))+geom_col(color = "darkgreen")+xlab("Hour") + ylab("Surplus (Deficit)") +ggtitle("Mean Surplus(Deficit) by Hour") 


#get count of each station for use as "index" to get a specified number of stations
hourcountedstation <- count(combinedcountbyhour, combinedcountbyhour$start.station.id)

#make a plot that shows surplus(deficit) by hour for 5 stations
head(combinedcountbyhour, n= sum(hourcountedstation[1:5,2]))%>%
ggplot(aes(x= hour, y= dif))+geom_col(color = "darkgreen")+facet_wrap("start.station.id")
```

## Holidays
```{r}
#make new df that counts start and end station by Holiday
startstationbyholiday <- count(datafortime, start.station.id, holiday)
endstationbyholiday <- count(datafortime, end.station.id, holiday)

#combine df's by station id and holiday
combinedcountbyholiday <- merge(startstationbyholiday, endstationbyholiday, by.x = c("start.station.id","holiday"), by.y = c("end.station.id","holiday"))

#find surplus(deficit) and make a new vector
combinedcountbyholiday$dif <- c(combinedcountbyholiday$n.x - combinedcountbyholiday$n.y)

#make a plot that shows average surplus(deficit) by holiday for all stations
group_by(combinedcountbyholiday, holiday, decreasing = TRUE)%>%
summarise(
  Dif = mean(dif, na.rm = TRUE))%>%
ggplot(aes(x = holiday, y= Dif))+geom_col(color = "darkgreen")+xlab("Holiday") + ylab("Surplus (Deficit)")+ggtitle("Mean Surplus(Deficit) by Holiday")  


#get count of each station for use as "index" to get a specified number of stations
holidaycountedstation <- count(combinedcountbyholiday, combinedcountbyholiday$start.station.id)

#make a plot that shows surplus(deficit) by holiday for 5 stations
head(combinedcountbyholiday, n= sum(holidaycountedstation[1:5,2]))%>%
ggplot(aes(x= holiday, y= dif))+geom_col(color = "darkgreen")+facet_wrap("start.station.id")+theme(axis.text.x = element_text(angle=90, hjust=1))
```

# Animation of Asymmetric Traffic
## Barplot
```{r}


#make an animation that shows surplus(deficit) for each day and leave a shadow 
surplusbarplot + transition_time(day) + labs(title = "Day: {frame_time}")  + shadow_wake(wake_length = 0.1, alpha = FALSE)

```

## Line Graph
```{r}
#make an animation that draws a line graph of surplus(deficit) for each day 
surplusplot + transition_reveal(day)
```

# Dynamic Pricing Model
## Static Limits Dynamic Pricing Model
Ignoring current pricing schemes, craft a new pricing model driven by asymmetric traffic. Assume after analyzing price data, maximum WTP = $8 and the minimum price city bike is willing to charge is $2.  
```{r}
#count number of times per usertype per hour that a start station is used
startstationbyroundedhour <- count(datafortime, start.station.id, usertype, roundedhour)

#count number of times per usertype per hour that a end station is used
endstationbyroundedhour <- count(datafortime, end.station.id, usertype, roundedhour)

#combine df's by station id and month
combinedcountbyroundedhour <- merge(startstationbyroundedhour, endstationbyroundedhour, by.x = c("start.station.id","usertype","roundedhour"), by.y = c("end.station.id","usertype","roundedhour"))

#find surplus(deficit) and make a new vector
combinedcountbyroundedhour$dif <- c(combinedcountbyroundedhour$n.x - combinedcountbyroundedhour$n.y)

library(fitdistrplus)
#see what fits best
#descdist(combinedcountbyroundedhour$dif)
norm_dist <- fitdist(combinedcountbyroundedhour$dif, "norm")
plot(norm_dist)
#appears that there are more extreme values than expected for a normal distribution

#assume when have full data, it will be closer to a true normal distribution
#static pricing scheme using normally distributed probabilities that weight a price between $2 and $8 based on surplus - incentivize people to rent from surplus stations
combinedcountbyroundedhour$pricing <- ifelse(8*(1-pnorm(combinedcountbyroundedhour$dif, mean(combinedcountbyroundedhour$dif, na.rm = TRUE), sd(combinedcountbyroundedhour$dif, na.rm = TRUE))) < 2, 2,8*(1-pnorm(combinedcountbyroundedhour$dif, mean(combinedcountbyroundedhour$dif, na.rm = TRUE), sd(combinedcountbyroundedhour$dif, na.rm = TRUE))))

#make new df that is filtered for station id in first row
combinedcountbyroundedstation <- combinedcountbyroundedhour[combinedcountbyroundedhour$start.station.id == combinedcountbyroundedhour[1,1],]

#head(combinedcountbyroundedhour[sort(combinedcountbyroundedhour$pricing, decreasing = TRUE),]) -> topcombindedcountbyroundedhour
#tail(combinedcountbyroundedhour[sort(combinedcountbyroundedhour$pricing, decreasing = TRUE),]) -> bottomcombinedcountbyroundedhour
#rbind(topcombindedcountbyroundedhour,bottomcombinedcountbyroundedhour)

#observe how surplus(deficit) is related to pricing scheme
ggplot(combinedcountbyroundedhour, aes(x=dif, y=pricing))+geom_line(colour = "darkgreen") + xlab("Surplus(Deficit)") + ylab("Price ($)") + ggtitle("Pricing to Surplus(Deficit)") 

#observe how price changes with surplus(deficit) by hour
ggplot(combinedcountbyroundedstation, aes(x = roundedhour))+geom_line(aes(y = pricing),color = "darkgreen") + geom_line(aes(y= dif),color = "yellowgreen")+scale_y_continuous(name = "Price ($)", sec.axis = sec_axis(~.*1, name ="Surplus(Deficit)"))+theme(axis.title.y = element_text(color = "darkgreen"), axis.title.y.right = element_text(color = "yellowgreen"))+ggtitle("Price and Surplus(Deficit) Hourly") 

```
## Embedded Rshiny Dynamic Pricing
```{r}
#allow user to change bounds of pricing scheme using rshiny
library(shiny)
shinyApp(

  #create user interface with min price and max price inputs and two outputs - one a plot of surplus to price and another a table of prices and related data given pricing criteria
  ui <- fluidPage(
      numericInput("MinPrice", "Enter Your Minimum Price Here", 2),
      numericInput("MaxPrice", "Enter Maximum Price Here", 8), 
      plotOutput("results"),
      dataTableOutput("list")
    ),
  
  #create server
  server <- function(input, output){
    
  #create reactive variable pricing that reacts to changing price input criteria
  pricing <- reactive({
    
   combinedcountbyroundedhour$pricing <- ifelse(input$MaxPrice*(1-pnorm(combinedcountbyroundedhour$dif, mean(combinedcountbyroundedhour$dif, na.rm = TRUE), sd(combinedcountbyroundedhour$dif, na.rm = TRUE))) < input$MinPrice, input$MinPrice,input$MaxPrice*(1-pnorm(combinedcountbyroundedhour$dif, mean(combinedcountbyroundedhour$dif, na.rm = TRUE), sd(combinedcountbyroundedhour$dif, na.rm = TRUE))))
  
  })
  
  #specify output plot - shows line graph of surplus(deficit) to pricing reactive variable
  output$results <- renderPlot({
  ggplot(combinedcountbyroundedhour,aes(x=dif, y=pricing()))+geom_line()
    })
  
  #specify output data table - shows pricing for changing price inputs
  output$list <- renderDataTable({
    cbind(pricing(), combinedcountbyroundedhour)
    
  })
},

#because embedding in rmarkdown, creating enough space for it to display
options = list(height = 500)
)
```

# Follow Bike
Follow bike 26483.
```{r}
#make new df with relevant vectors from sample
biketravels <- citibikesample[,c(3:5,7:9,11:13)]

#make uniquebike df which is for bikeid 26483 and arrange by increasing time
biketravels[sort(biketravels$starttime, descending = FALSE),] ->l
l[l$bikeid == 26483,] -> uniquebike

#format as ymdhms
uniquebike$starttime <- ymd_hms(uniquebike$starttime)
uniquebike$stoptime <- ymd_hms(uniquebike$stoptime)

#for loop to add moved to anywhere the end station is not the next start station
for (x in 1:nrow(uniquebike)) {
  uniquebike$travel[x] <- ifelse(uniquebike[x+1,3] == uniquebike[x,6],"Not Moved","Moved")
} 

#make df's for start and end lat/lon and times
startlocationlat <- as.data.frame(uniquebike[,4])
endlocationlat <- as.data.frame(uniquebike[,7])
startlocationlon <- as.data.frame(uniquebike[,5])
endlocationlon <- as.data.frame(uniquebike[,8])
starttime <- as.data.frame(uniquebike[,1])
endtime <- as.data.frame(uniquebike[,2])

library("schoolmath")

#define a as twice the length of vector so will go until both are entirely weaved
a <- 2*nrow(startlocationlat)

#make thing an empty df with doubles 
thing <- data.frame(Lat = double())

#make for loop to weave start and end lats together so that end is after start and store in df
for (x in 1:a) {
  ifelse(x==1, thing[x,1] <- startlocationlat[x,1],ifelse(is.even(x) == FALSE, thing[x,1]<-startlocationlat[(x-((x-1)/2)),1], thing[x,1] <- endlocationlat[(x-(x/2)),1]))
}  

#define b as twice the length of vector so will go until both are entirely weaved
b <- 2*nrow(startlocationlon)

#make thing1 an empty df with doubles
thing1 <- data.frame(Lon = double())

#make for loop to weave start and end lons together so that end is after start and store in df
for (x in 1:b) {
  ifelse(x==1, thing1[x,1] <- startlocationlon[x,1],ifelse(is.even(x) == FALSE, thing1[x,1]<-startlocationlon[(x-((x-1)/2)),1], thing1[x,1] <- endlocationlon[(x-(x/2)),1]))
} 

#define c as twice the length of vector so will go until both are entirely weaved
c <- 2*nrow(starttime)

#make timing an empty df with date format
timing <- data.frame(Time = POSIXct())

#make for loop to weave start and end times together so that end is after start and store in df
for (x in 1:c) {
  ifelse(x==1, timing[x,1] <- starttime[x,1],ifelse(is.even(x) == FALSE, timing[x,1]<-starttime[(x-((x-1)/2)),1], timing[x,1] <- endtime[(x-(x/2)),1]))
}  

#keep only first vector which is data that has been weaved together
finaltravellat <- data.frame(thing[,1])
finaltravellon <- data.frame(thing1[,1])
finaltime <- data.frame(timing[,1])

#combine weaved vectors into df
cbind(finaltime, finaltravellat, finaltravellon) -> pathbike

#get rid of duplicates
pathbikeunique <- unique(pathbike[order(pathbike$timing...1., decreasing = FALSE),])

#get map for nyc
citymap1 <- get_stamenmap(bbox = c(left = -74.03, bottom = 40.65, right = -73.87, top = 40.87), zoom = 12, maptype = c("terrain")) 

#display map and overlay point representing bike 
ggmap(citymap1) + geom_point(data=pathbikeunique, aes(x= thing1...1., y= thing...1.), colour = "blue", alpha = 0.5, size = 2)+geom_path() -> mapplot

#display animation by minute to track bike's movement and get a sense for the speed it traveled
mapplot + transition_reveal(pathbikeunique$timing...1.)
```























